{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8950798,"sourceType":"datasetVersion","datasetId":5386567},{"sourceId":8954223,"sourceType":"datasetVersion","datasetId":5388845},{"sourceId":8961984,"sourceType":"datasetVersion","datasetId":5394237},{"sourceId":9098939,"sourceType":"datasetVersion","datasetId":5393760}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install chardet\n!pip install seqeval -q\n!pip install nltk","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:26:57.296722Z","iopub.execute_input":"2024-08-04T08:26:57.297032Z","iopub.status.idle":"2024-08-04T08:27:39.106866Z","shell.execute_reply.started":"2024-08-04T08:26:57.297009Z","shell.execute_reply":"2024-08-04T08:27:39.105922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import the libraries / Modules","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\nimport gc\nimport json\nimport os\nimport random\nimport re\nimport warnings\nfrom collections import defaultdict\nfrom functools import partial\nfrom typing import Dict\n\nfrom sklearn.metrics import classification_report\nfrom seqeval.metrics import f1_score, precision_score, recall_score\n#from transformers import BertTokenizer, BertForSequenceClassification, AdamW, AutoTokenizer\nfrom transformers import (\n    BertTokenizer,\n    BertForSequenceClassification,\n    AdamW,\n    AutoModelForTokenClassification,\n    AutoTokenizer,\n    DataCollatorForTokenClassification,\n    Trainer,\n    TrainingArguments\n)\nimport torch\nfrom datasets import Dataset as HF_dataset\n#from torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:27:39.108969Z","iopub.execute_input":"2024-08-04T08:27:39.1093Z","iopub.status.idle":"2024-08-04T08:27:56.748508Z","shell.execute_reply.started":"2024-08-04T08:27:39.109252Z","shell.execute_reply":"2024-08-04T08:27:56.747742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set CFG and Seed","metadata":{}},{"cell_type":"code","source":"all_labels = [\n    \"O\",\n    'Task',\n    'Dataset',\n    'Metric',\n    'Score',\n]\nlabel2id = {l: i for i, l in enumerate(all_labels)}\nid2label = {v: k for k, v in label2id.items()}\n\nprint(id2label)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:27:56.749733Z","iopub.execute_input":"2024-08-04T08:27:56.75047Z","iopub.status.idle":"2024-08-04T08:27:56.756498Z","shell.execute_reply.started":"2024-08-04T08:27:56.750433Z","shell.execute_reply":"2024-08-04T08:27:56.75568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    # debug\n    debug = False\n    is_use_daniia_dataset = False\n\n    # cross validation\n    do_cv = True\n    fold = 0\n    n_splits = 2 if debug else 4\n\n    # gpu\n    gpu = torch.cuda.is_available()\n\n    # seed\n    seed = 42\n\n    # negative sample frac\n    neg_frac = 0 #0.3\n\n    # external dataset\n#     external_name = \"tonyarobertson\"\n    external_name = \"Last_epoch\" # \n#     external_name = \"mpware\"\n#     external_name = \"valentin\"\n#     external_name = \"moth\"\n#     external_name = \"pjmathematician\"\n    \n    #TODO adjust folders\n    # directory path\n    input_dir = \"/kaggle/working\"\n    comp_dir = input_dir + \"comp_dir\"\n    fold_dir = input_dir + \"sota/dataset/train/\"\n    external_dir = input_dir + \"external_dir\"\n    output_dir = \"/kaggle/working/output/\"\n\n    # file path\n    comp_path = comp_dir + \"train.json\"\n    external_path = external_dir + \"datamix.json\"\n\n    # tokenizer\n    train_max_length = 512 #1536\n    eval_max_length = 512 #3500\n    train_stride = None\n    eval_stride = 256\n\n    # model\n    # model_name = \"/kaggle/input/ready-dataset-negfrac0-0-lr3e-5/scibert_scivocab_uncased-Last_epoch-512-42-0\" #ALSO cased scibert\n    model_name = '/kaggle/input/ready-dataset-negfrac0-0-lr3e-5/output/checkpoint-12900'\n#     model_name = \"microsoft/deberta-v3-base\"\n#     model_name = \"microsoft/deberta-v3-large\"\n    num_train_epochs = 1 if debug else 3\n    max_steps = 5 if debug else 3000\n    fp16 = True if gpu else False\n    per_device_train_batch_size = 16\n    gradient_accumulation_steps = 1 \n    learning_rate = 3e-5\n    warmup_ratio = 0.1\n    weight_decay = 0.01\n\n    # postprocessing\n    threshold = 0.95\n\n    # save path\n    if train_stride is not None:\n        save_path = f\"{model_name.split('/')[-1]}-{external_name}-{train_max_length}-{train_stride}-{seed}\"\n    else:\n        save_path = f\"{model_name.split('/')[-1]}-{external_name}-{train_max_length}-{seed}\"\n    if do_cv:\n        save_path = f\"{save_path}-{fold}\"\n\ndef fix_seed(seed):\n    # basic\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n\n    # torch\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nfix_seed(Config.seed)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:15:33.899778Z","iopub.execute_input":"2024-08-04T10:15:33.900759Z","iopub.status.idle":"2024-08-04T10:15:33.913805Z","shell.execute_reply.started":"2024-08-04T10:15:33.900723Z","shell.execute_reply":"2024-08-04T10:15:33.912635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load data","metadata":{}},{"cell_type":"code","source":"# convert new str to new list\nfrom ast import literal_eval\ndef convert_str_to_list(row,term):\n    #if len(set(row[\"labels\"]))>1:\n    #    return True\n    #else:\n    #    return False\n    return literal_eval(row[term])\n    #return word_labels\nif not Config.is_use_daniia_dataset:\n    pass\n\n#    train_df_new['input_ids'] = train_df_new.apply(lambda row: convert_str_to_list(row,'input_ids'), axis=1)\n#    train_df_new['labels'] = train_df_new.apply(lambda row: convert_str_to_list(row,'labels'), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:27:01.135145Z","iopub.execute_input":"2024-08-04T09:27:01.135424Z","iopub.status.idle":"2024-08-04T09:27:01.140193Z","shell.execute_reply.started":"2024-08-04T09:27:01.135399Z","shell.execute_reply":"2024-08-04T09:27:01.139201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if Config.is_use_daniia_dataset:\n    val_df = pd.read_pickle('/kaggle/input/sota-preprocessed-v3/val_preprocessed_v2')[['input_ids','labels']]#[['word_labels','input_ids','token_type_ids','attention_mask','offset_mapping','labels']]\nelse:\n    val_df = pd.read_csv('../input/sota-all-ready/output_val_ready.csv')[['input_ids','labels']]\n    val_df['input_ids'] = val_df.apply(lambda row: convert_str_to_list(row,'input_ids'), axis=1)\n    val_df['labels'] = val_df.apply(lambda row: convert_str_to_list(row,'labels'), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:27:01.30857Z","iopub.execute_input":"2024-08-04T09:27:01.308918Z","iopub.status.idle":"2024-08-04T09:27:06.874495Z","shell.execute_reply.started":"2024-08-04T09:27:01.308888Z","shell.execute_reply":"2024-08-04T09:27:06.873505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# change label to O-0 task-1 dataset-2 metric-3 score-4, when use ready dataset no need\nif Config.is_use_daniia_dataset:\n    def change_label(row):\n        #print(row[\"labels\"],type(row[\"labels\"]))\n\n        #if len(set(row[\"labels\"]))>1:\n        #    return True\n        #else:\n        #    return False\n        #return word_labels\n        new_labels_list = [ii+1 for ii in row[\"labels\"]]\n        new_labels_list = [ii if ii!=5 else 0 for ii in new_labels_list]\n        #print(new_labels_list)\n        #raise ValueError()\n        return new_labels_list\n    #train_df_new['labels'] = train_df_new.apply(lambda row: change_label(row), axis=1)\n    val_df['labels'] = val_df.apply(lambda row: change_label(row), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:27:06.921998Z","iopub.execute_input":"2024-08-04T09:27:06.922291Z","iopub.status.idle":"2024-08-04T09:27:06.930309Z","shell.execute_reply.started":"2024-08-04T09:27:06.922268Z","shell.execute_reply":"2024-08-04T09:27:06.929506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(Config.model_name)\ndata_collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\nargs = TrainingArguments(\n    output_dir=Config.output_dir, \n    fp16=Config.fp16,\n    per_device_train_batch_size=Config.per_device_train_batch_size,\n    gradient_accumulation_steps=Config.gradient_accumulation_steps,\n    num_train_epochs=Config.num_train_epochs,\n#     max_steps=Config.max_steps,\n    learning_rate=0, #Config.learning_rate,\n    warmup_ratio=Config.warmup_ratio,\n    weight_decay=0, #Config.weight_decay,\n#     group_by_length=True,\n    #evaluation_strategy=\"no\",\n    evaluation_strategy='steps',\n    save_strategy='steps',\n    eval_steps=5 if Config.debug else 2,\n    save_steps=5 if Config.debug else 100,\n    logging_steps=0.05,\n    #save_strategy=\"no\",\n    save_total_limit=5,\n    lr_scheduler_type=\"cosine\",\n    metric_for_best_model=\"f1yue\",\n    load_best_model_at_end=True,\n    report_to=\"none\",\n    seed=Config.seed,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:27:06.931296Z","iopub.execute_input":"2024-08-04T09:27:06.931576Z","iopub.status.idle":"2024-08-04T09:27:07.014473Z","shell.execute_reply.started":"2024-08-04T09:27:06.931553Z","shell.execute_reply":"2024-08-04T09:27:07.013554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def freeze(module):\n    for parameter in module.parameters():\n        parameter.requires_grad = False\n\n\ndef compute_metrics(res, all_labels):\n    predictions, labels = res\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    recall = recall_score(true_labels, true_predictions)\n    precision = precision_score(true_labels, true_predictions)\n    f1_score = (1 + 1) * recall * precision / (1 * precision + recall)\n\n    return {\"recall\": recall, \"precision\": precision, \"f1yue\": f1_score}\n\n\ndef train(model_name, all_labels, id2label, label2id, ds, eval_ds, args, data_collator, tokenizer, save_path):\n    model = AutoModelForTokenClassification.from_pretrained(\n        model_name,\n        num_labels=len(all_labels),\n        id2label=id2label,\n        label2id=label2id,\n        ignore_mismatched_sizes=True,\n    )\n\n    trainer = Trainer(\n        model=model, \n        args=args, \n        train_dataset=ds,\n        eval_dataset=eval_ds,\n        data_collator=data_collator,\n        tokenizer=tokenizer,\n        compute_metrics=partial(compute_metrics, all_labels=all_labels)\n    )\n    \n    torch.cuda.empty_cache()\n    _ = gc.collect()\n    return model, trainer","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:27:07.01576Z","iopub.execute_input":"2024-08-04T09:27:07.016143Z","iopub.status.idle":"2024-08-04T09:27:07.027733Z","shell.execute_reply.started":"2024-08-04T09:27:07.016107Z","shell.execute_reply":"2024-08-04T09:27:07.026776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = HF_dataset.from_pandas(val_df, preserve_index=False)\nds_val = HF_dataset.from_pandas(val_df, preserve_index=False)\n\nmodel, trainer = train(\n    Config.model_name,\n    all_labels,\n    id2label,\n    label2id,\n    ds,\n    ds_val,\n    args,\n    data_collator,\n    tokenizer,\n    Config.save_path,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:15:43.308362Z","iopub.execute_input":"2024-08-04T10:15:43.308738Z","iopub.status.idle":"2024-08-04T10:15:48.902247Z","shell.execute_reply.started":"2024-08-04T10:15:43.308703Z","shell.execute_reply":"2024-08-04T10:15:48.901179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/sota-all-ready/output_test_ready.csv')[['input_ids','labels']]\ntest_df['input_ids'] = test_df.apply(lambda row: convert_str_to_list(row,'input_ids'), axis=1)\ntest_df['labels'] = test_df.apply(lambda row: convert_str_to_list(row,'labels'), axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:28:07.288472Z","iopub.execute_input":"2024-08-04T08:28:07.28875Z","iopub.status.idle":"2024-08-04T08:29:24.224296Z","shell.execute_reply.started":"2024-08-04T08:28:07.288725Z","shell.execute_reply":"2024-08-04T08:29:24.223522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_test = HF_dataset.from_pandas(test_df, preserve_index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:29:24.225392Z","iopub.execute_input":"2024-08-04T08:29:24.225704Z","iopub.status.idle":"2024-08-04T08:29:29.505253Z","shell.execute_reply.started":"2024-08-04T08:29:24.225678Z","shell.execute_reply":"2024-08-04T08:29:29.504468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate(ds_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:15:48.904247Z","iopub.execute_input":"2024-08-04T10:15:48.904935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -tl output","metadata":{"execution":{"iopub.status.busy":"2024-08-04T09:40:11.664649Z","iopub.execute_input":"2024-08-04T09:40:11.664952Z","iopub.status.idle":"2024-08-04T09:40:12.753931Z","shell.execute_reply.started":"2024-08-04T09:40:11.664925Z","shell.execute_reply":"2024-08-04T09:40:12.752686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DONE! ","metadata":{}}]}